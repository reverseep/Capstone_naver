{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d1cb03e048>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]], \n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(image.shape)\n",
    "plt.imshow(image.reshape(3,3), cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='VALID')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2,2))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(2,2), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 1)\n",
      "conv2d_img.shape (1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.]],[[1.]]],\n",
    "                      [[[1.]],[[1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,2,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape (1, 3, 3, 1)\n",
      "weight.shape (2, 2, 1, 3)\n",
      "conv2d_img.shape (1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"imag:\\n\", image)\n",
    "print(\"image.shape\", image.shape)\n",
    "\n",
    "weight = tf.constant([[[[1.,10.,-1.]],[[1.,10.,-1.]]],\n",
    "                      [[[1.,10.,-1.]],[[1.,10.,-1.]]]])\n",
    "print(\"weight.shape\", weight.shape)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1, 1, 1, 1], padding='SAME')\n",
    "conv2d_img = conv2d.eval()\n",
    "print(\"conv2d_img.shape\", conv2d_img.shape)\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3,3))\n",
    "    plt.subplot(1,3,i+1), plt.imshow(one_img.reshape(3,3), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='VALID')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[[[4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[2.]\n",
      "   [1.]]]]\n"
     ]
    }
   ],
   "source": [
    "image = np.array([[[[4],[3]],\n",
    "                    [[2],[1]]]], dtype=np.float32)\n",
    "pool = tf.nn.max_pool(image, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 1, 1, 1], padding='SAME')\n",
    "print(pool.shape)\n",
    "print(pool.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-a43f9f63cc55>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d1de8540b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_5:0\", shape=(1, 14, 14, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img = img.reshape(-1,28,28,1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 5], stddev=0.01))\n",
    "conv2d = tf.nn.conv2d(img, W1, strides=[1, 2, 2, 1], padding='SAME')\n",
    "print(conv2d)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "conv2d_img = conv2d.eval()\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(14,14), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_2:0\", shape=(1, 7, 7, 5), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pool = tf.nn.max_pool(conv2d, ksize=[1, 2, 2, 1], strides=[\n",
    "                        1, 2, 2, 1], padding='SAME')\n",
    "print(pool)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pool_img = pool.eval()\n",
    "pool_img = np.swapaxes(pool_img, 0, 3)\n",
    "for i, one_img in enumerate(pool_img):\n",
    "    plt.subplot(1,5,i+1), plt.imshow(one_img.reshape(7, 7), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-15-9c895553c5a9>:31: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Epoch: 0001 cost = 0.349303550\n",
      "Epoch: 0002 cost = 0.098451936\n",
      "Epoch: 0003 cost = 0.072221011\n",
      "Epoch: 0004 cost = 0.061433203\n",
      "Epoch: 0005 cost = 0.051616609\n",
      "Epoch: 0006 cost = 0.044650704\n",
      "Epoch: 0007 cost = 0.040392208\n",
      "Epoch: 0008 cost = 0.035861161\n",
      "Epoch: 0009 cost = 0.032525706\n",
      "Epoch: 0010 cost = 0.028355539\n",
      "Epoch: 0011 cost = 0.024863857\n",
      "Epoch: 0012 cost = 0.022373049\n",
      "Epoch: 0013 cost = 0.020726949\n",
      "Epoch: 0014 cost = 0.017297130\n",
      "Epoch: 0015 cost = 0.016717417\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D_6-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable_1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_6', defined at:\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-9c895553c5a9>\", line 15, in <module>\n    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D_6-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable_1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D_6-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable_1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-9c895553c5a9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mcorrect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;31m# Get one and predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D_6-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable_1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_6', defined at:\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-9c895553c5a9>\", line 15, in <module>\n    L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\renz\\AppData\\Local\\conda\\conda\\envs\\tensorflow3.6.5\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Conv2D_6-0-TransposeNHWCToNCHW-LayoutOptimizer, Variable_1/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: Mean_1/_13 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_48_Mean_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2_flat = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[7 * 7 * 64, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L2_flat, W3) + b\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={ X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost =  0.342191438\n",
      "Epoch:  0002 cost =  0.098262232\n",
      "Epoch:  0003 cost =  0.073345328\n",
      "Epoch:  0004 cost =  0.058955216\n",
      "Epoch:  0005 cost =  0.051215728\n",
      "Epoch:  0006 cost =  0.044548560\n",
      "Epoch:  0007 cost =  0.040828705\n",
      "Epoch:  0008 cost =  0.039470199\n",
      "Epoch:  0009 cost =  0.036123899\n",
      "Epoch:  0010 cost =  0.034605656\n",
      "Epoch:  0011 cost =  0.029684256\n",
      "Epoch:  0012 cost =  0.029568159\n",
      "Epoch:  0013 cost =  0.027369130\n",
      "Epoch:  0014 cost =  0.026643345\n",
      "Epoch:  0015 cost =  0.027689641\n",
      "Accuracy:  0.98\n",
      "Accuracy:  0.96\n",
      "Accuracy:  1.0\n",
      "Accuracy:  0.96\n",
      "Accuracy:  1.0\n",
      "Accuracy:  0.98\n",
      "Accuracy:  1.0\n",
      "Accuracy:  1.0\n",
      "Accuracy:  1.0\n",
      "Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])  #img 28*28*1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev = 0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev = 0.01))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3,3,64,128], stddev = 0.01))\n",
    "\n",
    "L3 = tf.nn.conv2d(L2, W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "L3= tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "L3 = tf.reshape(L3, [-1, 128*4*4])\n",
    "\n",
    "W4 = tf.get_variable('W4', shape = [4*4*128,625],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "W5 = tf.get_variable('W5', shape = [625, 10],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "#define cost/loss & optimizer\n",
    "learning_rate = 0.001\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis,\n",
    "                                                             labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "#train my model\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "for i in range(10):\n",
    "    testSet = mnist.test.next_batch(50)\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X:testSet[0], Y: testSet[1], keep_prob : 1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class로 model을 간결하게 구현하자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot = True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "        self._build_net()\n",
    "    \n",
    "    def _build_net(self):   #n = 5\n",
    "        with tf.variable_scope(self.name):\n",
    "            #input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, 784])\n",
    "            #img 28*28*1 (black/white)\n",
    "            X_img = tf.reshape(self.X, [-1, 28, 28, 1])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 10])\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "            #L1 ImgIn shape = (?, 28, 28, 1)\n",
    "            W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev = 0.01))\n",
    "            #    Conv     -> (?, 28, 28, 32)\n",
    "            #    Pool     -> (?, 14, 14, 32)\n",
    "            L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L1 = tf.nn.relu(L1)\n",
    "            L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=self.keep_prob)\n",
    "\n",
    "            # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "            W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "            #    Conv      ->(?, 14, 14, 64)\n",
    "            #    Pool      ->(?, 7, 7, 64)\n",
    "            L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L2 = tf.nn.relu(L2)\n",
    "            L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                                strides=[1, 2, 2, 1], padding='SAME')\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=self.keep_prob)\n",
    "\n",
    "            # L3 ImgIn shape=(?, 7, 7, 64)\n",
    "            W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "            #    Conv      ->(?, 7, 7, 128)\n",
    "            #    Pool      ->(?, 4, 4, 128)\n",
    "            #    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "            L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            L3 = tf.nn.relu(L3)\n",
    "            L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                                1, 2, 2, 1], padding='SAME')\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=self.keep_prob)\n",
    "\n",
    "            L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "\n",
    "            # L4 FC 4x4x128 inputs -> 625 outputs\n",
    "            W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([625]))\n",
    "            L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=self.keep_prob)\n",
    "\n",
    "            # L5 Final FC 625 inputs -> 10 outputs\n",
    "            W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                                 initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b5 = tf.Variable(tf.random_normal([10]))\n",
    "            self.logits = tf.matmul(L4, W5) + b5\n",
    "\n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=learning_rate).minimize(self.cost)\n",
    "\n",
    "        correct_prediction = tf.equal(\n",
    "            tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def predict(self, x_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test, keep_prop=1.0):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.keep_prob: keep_prop})\n",
    "\n",
    "    def train(self, x_data, y_data, keep_prop=0.7):\n",
    "        return self.sess.run([self.cost, self.optimizer], feed_dict={\n",
    "            self.X: x_data, self.Y: y_data, self.keep_prob: keep_prop})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Started!\n",
      "Epoch:  0001 cost =  0.391672520\n",
      "Epoch:  0002 cost =  0.091585207\n",
      "Epoch:  0003 cost =  0.069010094\n",
      "Epoch:  0004 cost =  0.056427574\n",
      "Epoch:  0005 cost =  0.050748391\n",
      "Epoch:  0006 cost =  0.043476240\n",
      "Epoch:  0007 cost =  0.042072330\n",
      "Epoch:  0008 cost =  0.036206245\n",
      "Epoch:  0009 cost =  0.037325306\n",
      "Epoch:  0010 cost =  0.031442440\n",
      "Epoch:  0011 cost =  0.031336346\n",
      "Epoch:  0012 cost =  0.031402338\n",
      "Epoch:  0013 cost =  0.025140492\n",
      "Epoch:  0014 cost =  0.026890303\n",
      "Epoch:  0015 cost =  0.024261917\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "m1 = Model(sess, 'm1')\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = m1.train(batch_xs, batch_ys)\n",
    "        avg_cost += c / total_batch\n",
    "    \n",
    "    print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-0.17962709,  0.06893022]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "import numpy as np\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "hidden_size = 2\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units= hidden_size)\n",
    "\n",
    "x_data = np.array([[[1,0,0,0]]], dtype = np.float32)\n",
    "outputs, _status = tf.nn.dynamic_rnn(cell, x_data, dtype = tf.float32)\n",
    "\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pp.pprint(outputs.eval(session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 4)\n",
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]]], dtype=float32)\n",
      "array([[[ 0.0168858 ,  0.0312864 ],\n",
      "        [-0.10008863,  0.05492236],\n",
      "        [-0.11125017, -0.12167816],\n",
      "        [-0.12911876, -0.2356927 ],\n",
      "        [-0.11376934, -0.20391332]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "#One cell RNN input_dim(4) -> output_dim (2), sequence: 5\n",
    "#one hot encoding\n",
    "h = [1,0,0,0]\n",
    "e = [0,1,0,0]\n",
    "l = [0,0,1,0]\n",
    "o = [0,0,0,1]\n",
    "\n",
    "hidden_size = 2\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size) #cell 생성\n",
    "x_data = np.array([[h, e, l, l,o]], dtype = np.float32)\n",
    "print(x_data.shape) #dim = 4, len = 5\n",
    "pp.pprint(x_data)\n",
    "\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, x_data, dtype = tf.float32) #y값들\n",
    "\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pp.pprint(outputs.eval(session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]],\n",
      "\n",
      "       [[0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.]]], dtype=float32)\n",
      "array([[[ 0.08549473, -0.02752551],\n",
      "        [ 0.02691756,  0.02521484],\n",
      "        [ 0.05831525,  0.02136325],\n",
      "        [ 0.07895692,  0.01699827],\n",
      "        [ 0.19066066, -0.0748955 ]],\n",
      "\n",
      "       [[-0.05041188,  0.0673624 ],\n",
      "        [ 0.09539095, -0.0240733 ],\n",
      "        [ 0.08061592, -0.01657841],\n",
      "        [ 0.09156995, -0.01201838],\n",
      "        [ 0.09725583, -0.00988409]],\n",
      "\n",
      "       [[ 0.04854891,  0.00802143],\n",
      "        [ 0.07406029,  0.00865404],\n",
      "        [ 0.01500892,  0.06152744],\n",
      "        [-0.04244129,  0.10738098],\n",
      "        [ 0.03015067,  0.08156554]]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x_data = np.array([[h, e, l, l, o],\n",
    "                  [e, o, l, l, l],\n",
    "                  [l,l,e,e,l]], dtype = np.float32)\n",
    "\n",
    "pp.pprint(x_data)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units = 2, state_is_tuple = True)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype = tf.float32)\n",
    "\n",
    "config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "sess = tf.Session(config = config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "pp.pprint(outputs.eval(session = sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "hidden_size = 5\n",
    "input_dim = 5\n",
    "batch_size = 1 #one sentence\n",
    "sequence_length = 6  \n",
    "\n",
    "idx2char = ['h', 'i', 'e','l', 'o']\n",
    "x_data = [[0,1,0,2,3,3]] \n",
    "x_one_hot = [[[1,0,0,0,0],\n",
    "              [0,1,0,0,0],\n",
    "              [1,0,0,0,0],\n",
    "              [0,0,1,0,0],\n",
    "              [0,0,0,1,0],\n",
    "              [0,0,0,1,0]]]\n",
    "\n",
    "y_data = [[1,0,2,3,3,4]] \n",
    "X = tf.placeholder(tf.float32, [None, sequence_length, input_dim]) #X one-hot\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units = hidden_size, state_is_tuple = True)\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, initial_state = initial_state, dtype = tf.float32)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss1:  0.5130153 Loss2:  0.37110072\n"
     ]
    }
   ],
   "source": [
    "y_data = tf.constant([[1,1,1]])\n",
    "\n",
    "prediction1 = tf.constant([[[0.3, 0.7],[0.3, 0.7], [0.3, 0.7]]], dtype = tf.float32)\n",
    "prediction2 = tf.constant([[[0.1,0.9],[0.1,0.9],[0.1,0.9]]], dtype = tf.float32)\n",
    "\n",
    "weights = tf.constant([[1,1,1]], dtype = tf.float32)\n",
    "\n",
    "sequence_loss1 = tf.contrib.seq2seq.sequence_loss(prediction1, y_data, weights)\n",
    "sequence_loss2 = tf.contrib.seq2seq.sequence_loss(prediction2, y_data, weights)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "print('Loss1: ', sequence_loss1.eval(session = sess), \n",
    "     'Loss2: ', sequence_loss2.eval(session = sess))\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow3.6.5]",
   "language": "python",
   "name": "conda-env-tensorflow3.6.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
